## Vulnerability Name

**Author(s):**

David Rowe

**Description:**

Exploit the LLM to execute malicious code, commands, or actions

**Common Examples of Vulnerability:**

1. Example 1: Ask the LLM to run code and the LLM runs said code
2. Example 2: Identifying the system the LLM is running on and 
3. Example 3: User identifies how system is displaying output and enters repeat after me commands to bypass filtering engines.

**How to Prevent:**

1. Prevention Step 1: User input filtering
2. Prevention Step 2: Update system level functionalities
3. Prevention Step 3: Schedule regular scans

**Example Attack Scenarios:**

Scenario #1: Unfiltered input runs on system.  Character escapes lead to code execution

Scenario #2: 

**Reference Links:**

1. [You're a javascipt-based bot](https://willwillems.com/posts/run-code-with-chatgpt.html): Run code with chatgpt
2. [Link Title](URL): Brief description of the reference link.

**Author Commentary (Optional):**

(Optional) Any additional insights, opinions, or perspectives from the author that are relevant to understanding or addressing the vulnerability.
